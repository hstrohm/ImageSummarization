{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joseph\\Anaconda3\\envs\\nlp\\lib\\runpy.py:193: UserWarning: [W019] Changing vectors name from en_core_web_lg.vectors to en_core_web_lg.vectors_1070971, to avoid clash with previously loaded vectors. See Issue #3853.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1fb98370128>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://spacy.io/usage/vectors-similarity\n",
    "\n",
    "# install spacy\n",
    "# install torchtext\n",
    "\n",
    "import spacy\n",
    "import torchtext\n",
    "import json\n",
    "\n",
    "# python -m spacy download\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "spacy.load('en_vectors_web_lg', vocab=nlp.vocab)\n",
    "\n",
    "# Have project be a few scripts to run to avoid having everything in one environment\n",
    "# (also that would be a lot in memory)\n",
    "# (but mainly I don't want to put everything on one environment rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lists\n",
    "with open('results.json', 'r') as it:\n",
    "    results = json.load(it)\n",
    "\n",
    "with open('failed.json', 'r') as it:\n",
    "    failed = json.load(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Testing Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bicycle True 6.655211 True\n",
      "human True 6.869779 True\n",
      "top True 5.5138364 True\n",
      "on True 5.218119 True\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp('bicycle human top on')\n",
    "\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bicycle human 0.18300328\n",
      "bicycle top 0.16640997\n",
      "bicycle on 0.233741\n",
      "human bicycle 0.18300328\n",
      "human top 0.18022928\n",
      "human on 0.25648427\n",
      "top bicycle 0.16640997\n",
      "top human 0.18022928\n",
      "top on 0.385453\n",
      "on bicycle 0.233741\n",
      "on human 0.25648427\n",
      "on top 0.385453\n"
     ]
    }
   ],
   "source": [
    "[print(token1.text, token2.text, token1.similarity(token2)) for token1 in tokens for token2 in tokens if token1 != token2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human is on bike.\n",
      "Human is on top of bike.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Human is on bike. Human is on top of bike.\"\n",
    "hi = nlp(text)\n",
    "sentences = list(hi.sents) # list of sentences\n",
    "\n",
    "for sent in sentences:\n",
    "    print(sent)\n",
    "sent.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bottle', 'person', 'pizza'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = set()\n",
    "for row in results: # grab each word from results\n",
    "    words.add(row[0])\n",
    "    words.add(row[1])\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2141891835424058"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(results[0][0]).similarity(nlp(results[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to find the 'best' sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person is to the right of pizza\n",
      "person is to the left of pizza\n",
      "bottle is beside pizza\n",
      "person is to the left of person\n",
      "person is to the right of person\n",
      "person is holding bottle\n",
      "person is holding bottle\n"
     ]
    }
   ],
   "source": [
    "# Construct the \"best\" sentence\n",
    "for i in range(len(results)):\n",
    "\n",
    "    word1 = nlp(results[i][0])\n",
    "    word2 = nlp(results[i][1])\n",
    "\n",
    "    prep_similarity = {}\n",
    "    for prep in results[i][4]:\n",
    "        #print(prep)\n",
    "        nlprep = nlp(prep)\n",
    "\n",
    "        avg = nlprep.similarity(word1) + nlprep.similarity(word2)\n",
    "        avg = avg / 2\n",
    "\n",
    "        #print(\"{:.4f}\".format(avg))\n",
    "        prep_similarity[prep] = avg\n",
    "\n",
    "    prep = max(prep_similarity, key = prep_similarity.get)\n",
    "\n",
    "    # might just want the first one\n",
    "    if word1.similarity(nlp(prep)) > word2.similarity(nlp(prep)):\n",
    "        sentence = word1.text + \" \" + prep + \" \" + word2.text\n",
    "    else:\n",
    "        sentence = word2.text + \" \" + prep + \" \" + word1.text\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[bottle is beside person.,\n",
       " person is beside bottle.,\n",
       " bottle is to the,\n",
       " right of person.,\n",
       " person is to the,\n",
       " right of bottle.,\n",
       " bottle is adjacent to person.,\n",
       " person is adjacent to bottle.,\n",
       " bottle is holding person.,\n",
       " person is holding bottle.,\n",
       " bottle overlaps person.,\n",
       " person overlaps bottle]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or pick the \"best\" sentence ... not sure how yet\n",
    "# just getting all sentences right now\n",
    "i = 0\n",
    "\n",
    "sentences = []\n",
    "for prep in results[i][4]:\n",
    "    sentences.append(word1.text + \" \" + prep + \" \" + word2.text)\n",
    "    sentences.append(word2.text + \" \" + prep + \" \" + word1.text)\n",
    "\n",
    "nl = nlp(\". \".join(sentences))\n",
    "sents = list(nl.sents)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
