{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joseph\\Anaconda3\\envs\\nlp\\lib\\runpy.py:193: UserWarning: [W019] Changing vectors name from en_core_web_lg.vectors to en_core_web_lg.vectors_1070971, to avoid clash with previously loaded vectors. See Issue #3853.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1d8157476d8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://spacy.io/usage/vectors-similarity\n",
    "\n",
    "# install spacy\n",
    "# install torchtext\n",
    "\n",
    "import spacy\n",
    "import torchtext\n",
    "import json\n",
    "\n",
    "# python -m spacy download\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "spacy.load('en_vectors_web_lg', vocab=nlp.vocab)\n",
    "\n",
    "# Have project be a few scripts to run to avoid having everything in one environment\n",
    "# (also that would be a lot in memory)\n",
    "# (but mainly I don't want to put everything on one environment rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get lists\n",
    "with open('results.json', 'r') as it:\n",
    "    results = json.load(it)\n",
    "\n",
    "with open('failed.json', 'r') as it:\n",
    "    failed = json.load(it)\n",
    "    \n",
    "with open('everything.json', 'r') as it:\n",
    "    everything = json.load(it)\n",
    "len(everything)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Testing Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bicycle True 6.655211 True\n",
      "human True 6.869779 True\n",
      "top True 5.5138364 True\n",
      "on True 5.218119 True\n"
     ]
    }
   ],
   "source": [
    "tokens = nlp('bicycle human top on')\n",
    "\n",
    "for token in tokens:\n",
    "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bicycle human 0.18300328\n",
      "bicycle top 0.16640997\n",
      "bicycle on 0.233741\n",
      "human bicycle 0.18300328\n",
      "human top 0.18022928\n",
      "human on 0.25648427\n",
      "top bicycle 0.16640997\n",
      "top human 0.18022928\n",
      "top on 0.385453\n",
      "on bicycle 0.233741\n",
      "on human 0.25648427\n",
      "on top 0.385453\n"
     ]
    }
   ],
   "source": [
    "[print(token1.text, token2.text, token1.similarity(token2)) for token1 in tokens for token2 in tokens if token1 != token2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bicycle top 0.16640997\n",
      "bicycle on 0.233741\n",
      "human top 0.18022928\n",
      "human on 0.25648427\n"
     ]
    }
   ],
   "source": [
    "l = [\n",
    "'bicycle top 0.16640997',\n",
    "'bicycle on 0.233741',\n",
    "'human top 0.18022928',\n",
    "'human on 0.25648427']\n",
    "\n",
    "for i in l:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human is on bike.\n",
      "Human is on top of bike.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Human is on bike. Human is on top of bike.\"\n",
    "hi = nlp(text)\n",
    "sentences = list(hi.sents) # list of sentences\n",
    "\n",
    "for sent in sentences:\n",
    "    print(sent)\n",
    "sent.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bowl', 'orange'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = set()\n",
    "for row in results: # grab each word from results\n",
    "    words.add(row[0])\n",
    "    words.add(row[1])\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(results[0][0]).similarity(nlp(results[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to find the 'best' sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orange is beside orange\n",
      "orange is beside orange\n",
      "orange is on top of orange\n",
      "orange is on top of bowl\n",
      "orange is beside orange\n",
      "orange is beside orange\n",
      "bowl is holding orange\n",
      "orange is beside orange\n",
      "orange is beside orange\n",
      "bowl is holding orange\n",
      "orange is beside orange\n",
      "orange is beside orange\n"
     ]
    }
   ],
   "source": [
    "# Construct the \"best\" sentence\n",
    "for i in range(len(results)):\n",
    "\n",
    "    word1 = nlp(results[i][0])\n",
    "    word2 = nlp(results[i][1])\n",
    "\n",
    "    prep_similarity = {}\n",
    "    for prep in results[i][4]:\n",
    "        #print(prep)\n",
    "        nlprep = nlp(prep)\n",
    "\n",
    "        avg = nlprep.similarity(word1) + nlprep.similarity(word2)\n",
    "        avg = avg / 2\n",
    "\n",
    "        #print(\"{:.4f}\".format(avg))\n",
    "        prep_similarity[prep] = avg\n",
    "\n",
    "    prep = max(prep_similarity, key = prep_similarity.get)\n",
    "\n",
    "    # might just want the first one\n",
    "    if word1.similarity(nlp(prep)) > word2.similarity(nlp(prep)):\n",
    "        sentence = word1.text + \" \" + prep + \" \" + word2.text\n",
    "    else:\n",
    "        sentence = word2.text + \" \" + prep + \" \" + word1.text\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[orange is beside orange.,\n",
       " orange is beside orange.,\n",
       " orange is to the left of orange.,\n",
       " orange is to the left of orange.,\n",
       " orange is adjacent to orange.,\n",
       " orange is adjacent to orange.,\n",
       " orange is holding orange.,\n",
       " orange is holding orange.,\n",
       " orange overlaps orange.,\n",
       " orange overlaps orange]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or pick the \"best\" sentence ... not sure how yet\n",
    "# just getting all sentences right now\n",
    "i = 0\n",
    "\n",
    "sentences = []\n",
    "for prep in results[i][4]:\n",
    "    sentences.append(word1.text + \" \" + prep + \" \" + word2.text)\n",
    "    sentences.append(word2.text + \" \" + prep + \" \" + word1.text)\n",
    "\n",
    "nl = nlp(\". \".join(sentences))\n",
    "sents = list(nl.sents)\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the \"best\" sentence\n",
    "# Put color in sentences\n",
    "def getBestSentences(results, colors, labels):\n",
    "    sentences = []\n",
    "    indices = set() # put index here once it's gotten a color in a sentence\n",
    "    many = set()\n",
    "    \n",
    "    for i in range(len(results)):\n",
    "        word1 = nlp(results[i][0])\n",
    "        word2 = nlp(results[i][1])\n",
    "        \n",
    "        # Get article to use (takes care of punctuation as well)\n",
    "        art1 = \"A\" if labels.count(word1.text) > 1 else \"The\"\n",
    "        art2 = \"a\" if labels.count(word1.text) > 1 else \"the\"\n",
    "        \n",
    "        # If first time running into this label\n",
    "        if results[i][2] not in indices:\n",
    "            color1 = colors[results[i][2]]\n",
    "            if word1.text != \"person\": art1 = art1 + \" \" + color1\n",
    "            indices.add(results[i][2])\n",
    "            \n",
    "            if labels.count(word1.text) > 3 and word1.text not in many:\n",
    "                adj = \"multiple\"\n",
    "                if labels.count(word1.text) > 5: adj = \"many\"\n",
    "                if word1.text != \"person\":\n",
    "                    sentences.append(\"There are \" + adj + \" \" + color1 + \" \" + word1.text + \".\")\n",
    "                else:\n",
    "                    sentences.append(\"There are \" + adj +  \" \" + word1.text + \".\")\n",
    "                many.add(word1.text)\n",
    "                continue\n",
    "            \n",
    "        if results[i][3] not in indices:\n",
    "            color2 = colors[results[i][3]]\n",
    "            if word2.text != \"person\": art2 = art2 + \" \" + color2\n",
    "            indices.add(results[i][3])\n",
    "            \n",
    "            if labels.count(word2.text) > 3 and word2.text not in many:\n",
    "                adj = \"multiple\"\n",
    "                if labels.count(word2.text) > 5: adj = \"many\"\n",
    "                if word2.text != \"person\":\n",
    "                    sentences.append(\"There are \" + adj + \" \" + color2 + \" \" + word2.text + \".\")\n",
    "                else:\n",
    "                    sentences.append(\"There are \" + adj +  \" \" + word2.text + \".\")\n",
    "                many.add(word2.text)\n",
    "                continue\n",
    "        \n",
    "        if word1.text in many and word2.text in many: continue\n",
    "        \n",
    "        # Find best preposition\n",
    "        prep_similarity = {}\n",
    "        for prep in results[i][4]:\n",
    "            nlprep = nlp(prep)\n",
    "            \n",
    "            avg = nlprep.similarity(word1) + nlprep.similarity(word2)\n",
    "            avg = avg / 2\n",
    "            \n",
    "            prep_similarity[prep] = avg\n",
    "            \n",
    "        prep = max(prep_similarity, key = prep_similarity.get) # get preposition\n",
    "        sentence = art1 + \" \" + word1.text + \" \" + prep + \" \" + art2 + \" \" + word2.text + \".\" # make sentence\n",
    "        sentences.append(sentence)\n",
    "    \n",
    "    if len(sentences) == 0:\n",
    "        c = getColorSentences(colors, labels)\n",
    "        return c, c\n",
    "    elif len(sentences) > 5:\n",
    "        short = sentences[:5].copy()\n",
    "        return short, sentences\n",
    "    \n",
    "    return sentences, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the \"best\" sentence\n",
    "# Add color sentences after\n",
    "\n",
    "def getColorSentences(colors, labels):\n",
    "    sentences = []\n",
    "    many = set()\n",
    "    for i in range(len(colors)):\n",
    "        art = \"A\" if labels.count(labels[i]) > 1 else \"The\"\n",
    "        \n",
    "        if labels[i] == 'person': continue\n",
    "        \n",
    "        if labels.count(labels[i]) > 3 and labels[i] not in many:\n",
    "            many.add(labels[i])\n",
    "            adj = \"multiple\"\n",
    "            if labels.count(labels[i]) > 5: adj = \"many\"\n",
    "            sentences.append(\"There are \" + adj + \" \" + colors[results[i][3]] + \" \" + labels[i] + \".\")\n",
    "            continue\n",
    "        \n",
    "        sentence = art + \" \" + labels[i] + \" is \" + colors[i] + \".\"\n",
    "        sentences.append(sentence)\n",
    "        \n",
    "    return sentences\n",
    "\n",
    "def getBestSentences2(results, colors, labels):\n",
    "    sentences = []\n",
    "    many = set()\n",
    "    \n",
    "    for i in range(len(results)):\n",
    "        word1 = nlp(results[i][0])\n",
    "        word2 = nlp(results[i][1])\n",
    "        \n",
    "        art1 = \"A\" if labels.count(word1.text) > 1 else \"The\"\n",
    "        art2 = \"a\" if labels.count(word1.text) > 1 else \"the\"\n",
    "        \n",
    "        if labels.count(word1.text) > 3 and word1.text not in many:\n",
    "            many.add(word1.text)\n",
    "            # getColorSentences takes care of adding this sentence\n",
    "            continue\n",
    "        \n",
    "        if labels.count(word2.text) > 3 and word2.text not in many:\n",
    "            many.add(word2.text)\n",
    "            # getColorSentences takes care of adding this sentence\n",
    "            continue\n",
    "        \n",
    "        # Find best preposition\n",
    "        prep_similarity = {}\n",
    "        for prep in results[i][4]:\n",
    "            nlprep = nlp(prep)\n",
    "\n",
    "            avg = nlprep.similarity(word1) + nlprep.similarity(word2)\n",
    "            avg = avg / 2\n",
    "\n",
    "            prep_similarity[prep] = avg\n",
    "\n",
    "        prep = max(prep_similarity, key = prep_similarity.get) # get preposition\n",
    "        sentence = art1 + \" \" + word1.text + \" \" + prep + \" \" + art2 + \" \" + word2.text + \".\" # make sentence\n",
    "        sentences.append(sentence)\n",
    "    \n",
    "    c = getColorSentences(colors, labels)\n",
    "    if len(sentences) > 5:\n",
    "        shorts = sentences[:5].copy()\n",
    "        shorts.extend(c)\n",
    "        sentences.extend(c)\n",
    "        return shorts, sentences\n",
    "    \n",
    "    sentences.extend(c)\n",
    "    return sentences, sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# everything[i] = [row, results, failed, colorsForRetBoxes, retLabels, retScores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_short_results = []\n",
    "final_results = []\n",
    "\n",
    "for row, results, failed, colors, labels, scores in everything:\n",
    "    short1, sentences1 = getBestSentences(results, colors, labels)\n",
    "    short2, sentences2 = getBestSentences2(results, colors, labels)\n",
    "    \n",
    "    final_short_results.append([row, \" \".join(short1), \" \".join(short2)])\n",
    "    final_results.append([row, \" \".join(sentences1), \" \".join(sentences2)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11,\n",
       " 'There are many person. A black cell phone is to the right of a person. A cell phone is to the left of a person. A cell phone is to the right of a person. A cell phone is adjacent to a lightgrey cell phone.',\n",
       " 'A person is below a person. A person is to the right of a person. A person is to the left of a person. A person is to the left of a person. A person is to the left of a person. A cell phone is black. A cell phone is lightgrey.']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_short_results[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final_short_results.json', 'w') as ot:\n",
    "    json.dump(final_short_results, ot)\n",
    "\n",
    "with open('final_long_results.json', 'w') as ot:\n",
    "    json.dump(final_results, ot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
